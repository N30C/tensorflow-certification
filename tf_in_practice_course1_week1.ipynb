{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_in_practice_course1_week1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eSC3tQnIi_uf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             keras.layers.Dense(units = 1, input_shape = [1])\n",
        "                             ])\n",
        "\n",
        "model.compile(optimizer = 'sgd', loss = 'mean_squared_error') #With adam it fails to optimize weights"
      ],
      "metadata": {
        "id": "Sd7p4GG_JZp-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "metadata": {
        "id": "xpfN5lHvL9t6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimize data\n",
        "# 1. Turn train and test arrays into tensor Datasets\n",
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(xs)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(ys)\n",
        "\n",
        "# 2. Combine features & labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "\n",
        "# 3. Batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5snNslmzML3c"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xs, ys, epochs = 500, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izFzb-jML_p3",
        "outputId": "2d075682-9015-4bfd-8854-a37498a45ea2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6ea00823d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([10.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H-o6ecsMGl5",
        "outputId": "7f2ec013-4b5c-4191-c46b-9627c73c8eec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18.983942]]\n"
          ]
        }
      ]
    }
  ]
}